{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Копия блокнота \"Seminar_02task.ipynb\"","provenance":[{"file_id":"1Yj2k-yi7sG-C7dt07Dr0C9d1vtjE-BZo","timestamp":1598221563093}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TDqfgGd0bL3C"},"source":["# Семинар 2: Обзор сред. Q-обучение. Апроксимация Q-функции. \n","\n","## 1. Обзор сред\n","\n","* [Classic Control](https://gym.openai.com/envs/#classic_control)\n","* [Box2D](https://gym.openai.com/envs/#box2d)\n","* [Atari](https://gym.openai.com/envs/#atari)\n","* [Gym Retro](https://openai.com/blog/gym-retro/)\n","* [Mujoco](https://gym.openai.com/envs/#mujoco)\n","* [Robotics](https://gym.openai.com/envs/#robotics)\n","* [Universe](https://openai.com/blog/universe/)\n","* [MineRL](https://minerl.io/) \\(использует проект [malmo](https://www.microsoft.com/en-us/research/project/project-malmo/))\n","* [Starcraft II](https://github.com/deepmind/pysc2)\n","* [Biomechanics: Learning to move](https://www.aicrowd.com/challenges/neurips-2019-learning-to-move-walk-around)\n","* [Procgen](https://openai.com/blog/procgen-benchmark/)\n","* [Halitate on Kaggle](https://www.kaggle.com/c/halite) \n","* [Flatland](https://www.aicrowd.com/challenges/neurips-2020-flatland-challenge)\n","* Настольные игры: Chess, GO и т.д. (множество среда на github)\n","* [Learning to Run a Power Network](https://competitions.codalab.org/competitions/20767) \\(ссылка на [NIPS](https://nips.cc/Conferences/2020/CompetitionTrack))\n","* ...\n","\n","## Краткое повторение\n","<img src=\"https://github.com/hse-ds/iad-applied-ds/raw/master/2020/seminars/seminar15/rlIntro.png\" caption=\"Взаимодействия агента со средой\" style=\"width: 300px;\" />\n","\n","Основные составляющие модели RL:\n","* $s_t$ -- состояние среды в момент времени $t$,\n","* $a_t$ -- действие, совершаемое агентом в момент времени $t$,\n","* $r_t$ -- вознаграждение, получаемое агентом при совершении действия $a_t$,\n","* $\\pi$ -- стратегия, отвечает за выбор действия в конкретном состоянии.\n","\n","Марковский процесс принятия решений\n","В простейших моделях RL среда представляется в виде марковского процесса принятия решений (MDP), где функция перехода определяется как $P(s' |s,a)$, что означает вероятность оказаться в состоянии $s'$ при совершении действия $a$ в состоянии $s$. Вознаграждение теперь определяется как $r(s,a,s')$.\n","\n","<img src=\"https://github.com/hse-ds/iad-applied-ds/raw/master/2020/seminars/seminar15/mdp.png\" caption=\"Марковский процесс принятия решений\" style=\"width: 400px;\"/>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ajUaHPOJH-3Z"},"source":["## 2. Q-обучение\n"]},{"cell_type":"markdown","metadata":{"id":"fIX-e9zJKk23","colab_type":"text"},"source":["Одним из наиболее популярных алгоритм обучения на основе временных различий является Q-обучение.Уравнение Беллмана для значения Q-функции записывается как:\n","\n","$$Q(s,a)=r(s)+\\gamma\\sum_s'T(s,a,s')\\max_{a'}Q(a',s')$$\n","\n","Уравнение для итерационного обновления значений Q-функции выглядит следующим образом:$$Q(s,a)\\leftarrow Q(s,a)+\\alpha \\big (r(s)+\\gamma\\max_{a'}Q(a',s') - Q(s,a) \\big ).$$\n","\n","Раскроем скобки:\n","$$Q(s,a)\\leftarrow (1 - \\alpha) \\times Q(s,a)+\\alpha \\times \\big (r(s)+\\gamma\\max_{a'}Q(a',s')\\big ).$$\n","\n","Ничего не напоминает?"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WJ79cSTLLPb-"},"source":["Для обучения будем использовать среду Taxi-v3. Подробнее про данное окружение можно посмотреть в документации: https://gym.openai.com/envs/Taxi-v3/."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ud0_kfOGLUwo","colab":{}},"source":["# не забудьте включить GPU в runtime\n","import gym\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uwqXBprJKk26","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1596734708636,"user_tz":-180,"elapsed":2073,"user":{"displayName":"Alexey Skrynnik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb-e3rfdb-9cH-pDpsbPoNsHTSCgRXXeyYsgnk=s64","userId":"17884625855310505059"}},"outputId":"0894b2d4-73bf-42b2-da9e-aa94d3a23b1a"},"source":["env = gym.make(\"Taxi-v3\")\n","env.render()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---------+\n","|R: | : :\u001b[34;1m\u001b[43mG\u001b[0m\u001b[0m|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Phe3a5aTQBsd","colab":{}},"source":["def show_progress(rewards_batch, log, reward_range=None):\n","    \"\"\"\n","    Удобная функция, которая отображает прогресс обучения.\n","    \"\"\"\n","\n","    if reward_range is None:\n","        reward_range = [-990, +10]\n","    mean_reward = np.mean(rewards_batch)\n","    log.append([mean_reward])\n","\n","    clear_output(True)\n","    plt.figure(figsize=[8, 4])\n","    plt.subplot(1, 2, 1)\n","    plt.plot(list(zip(*log))[0], label='Mean rewards')\n","    plt.legend(loc=4)\n","    plt.grid()\n","    plt.grid()\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m_Pbvpm4Kk2-","colab_type":"text"},"source":["### Задание 1\n","\n","Создайте таблицу из нулей, используя информацию из окружения о количестве состояний и действий"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_bddYTsDQmVL","colab":{}},"source":["import random\n","from IPython.display import clear_output\n","\n","# гиперпараметры алгоритма\n","alpha = 0.1\n","gamma = 0.95\n","epsilon = 0.1\n","episodes_number = 10001"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8QjwLO_CKk3B","colab_type":"code","colab":{}},"source":["def initialize_q_table(env):\n","    # подсказка смотрим env.observation_space и env.action_space\n","    # q_table_ = [state][action]\n","    ####### Здесь ваш код ##########\n","    q_table_ = np.zeros([env.observation_space.n, env.adef initialize_q_table(env):\n","    # подсказка смотрим env.observation_space и env.action_space\n","    # q_table_ = [state][action]\n","    ####### Здесь ваш код ##########\n","    q_table_ = np.zeros([env.observation_space.n, env.action_space.n])\n","    ################################\n","    return q_table_ction_space.n])\n","    ################################\n","    return q_table_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pG9YEmftQtu0"},"source":["### Задание 2\n","\n","Напишите код для формулы Q-обновления, используя известные: alpha, reward, gamma, next_max, old_value (q_table[state, action])"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DUthRLiaIuuV","colab":{}},"source":["# определяем память, в которой будет храниться Q(s,a)\n","q_table = initialize_q_table(env)\n","log = []\n","rewards_batch = []\n","\n","for i in range(1, episodes_number):\n","    state = env.reset()\n","\n","    episode, reward, episode_reward = 0, 0, 0\n","    done = False\n","    \n","    while not done:\n","        # выбираем действие, используя eps-greedy исследование среды\n","        # с вероятностью epsilon выбираем случайное действие, иначе \n","        # выполняем действие жадно, согласно текущей Q-таблице \n","        # action = \n","        ####### Здесь ваш код ##########\n","        if random.uniform(0, 1) < epsilon:\n","            action = env.action_space.sample() # исследуем среду\n","        else:\n","            action = np.argmax(q_table[state]) # используем Q-функцию\n","        ################################\n","        \n","        # выполняем действие в среде \n","        next_state, reward, done, info = env.step(action) \n","        \n","        # получаем old_value (Q(s,a)) и next_max (max(Q(s', a')))\n","        old_value = q_table[state, action]\n","        next_max = np.max(q_table[next_state])\n","        \n","        # код для Q-обновления\n","        # new_value = \n","        ####### Здесь ваш код ##########\n","        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n","        ################################\n","        \n","        q_table[state, action] = new_value\n","\n","        state = next_state\n","        episode += 1\n","        episode_reward += reward\n","    rewards_batch.append(episode_reward)\n","     \n","    if i % 100 == 0:\n","        show_progress(rewards_batch, log)\n","        rewards_batch = []\n","        print(f\"Episode: {i}, Reward: {episode_reward}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QCvfdLORQOf0"},"source":["Если все сделано правильно, то график должен выйти на плато около 0. А значение вознаграждение будет в диапазоне [-5, 10], за счет случайного выбора начальной позиции такси и пассажира. Попробуйте изменить гиперпараметры и сравните результаты."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"f7sfWBeBq8Wx"},"source":["## 3. Аппроксимация Q-функции\n","\n","В данном пункте мы будем использовать библиотеку tensorflow для обучения нейронной сети, хотя можно использовать и любую другую библиотеку."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5BFkc4eN16Lh","colab":{}},"source":["import sys, os\n","import gym\n","import random\n","if 'google.colab' in sys.modules:\n","    %tensorflow_version 1.x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YRnOxiAZrOFN","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596736648565,"user_tz":-180,"elapsed":602,"user":{"displayName":"Alexey Skrynnik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb-e3rfdb-9cH-pDpsbPoNsHTSCgRXXeyYsgnk=s64","userId":"17884625855310505059"}},"outputId":"c1997fbd-4056-425d-cf19-8f86dc98ef19"},"source":["env = gym.make(\"CartPole-v0\")\n","s = env.reset()\n","n_actions = env.action_space.n\n","state_dim = env.observation_space.shape\n","\n","print(state_dim)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(4,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cYbIV7w42Fp1"},"source":["Так как описание состояния в задаче с маятником представляет собой не \"сырые\" признаки, а уже предобработанные (координаты, углы), нам не нужна для начала сложная архитектура, начнем с такой:\n","<img src=\"https://github.com/hse-ds/iad-applied-ds/raw/master/2020/seminars/seminar15/qapp.png\">\n","Для начала попробуйте использовать только полносвязные слои (L.Dense) и простые активационные функции. Сигмоиды и другие функции не будут работать с ненормализованными входными данными."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4kjlhlAP4rcf","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596737975729,"user_tz":-180,"elapsed":7511,"user":{"displayName":"Alexey Skrynnik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb-e3rfdb-9cH-pDpsbPoNsHTSCgRXXeyYsgnk=s64","userId":"17884625855310505059"}},"outputId":"88b27cb9-6e73-4c52-fb3f-91af51745e8a"},"source":["import tensorflow as tf\n","import keras\n","import keras.layers as L\n","import numpy as np\n","\n","tf.reset_default_graph()\n","sess = tf.InteractiveSession()\n","keras.backend.set_session(sess)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yjFU7TXz4sD7","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1596737976110,"user_tz":-180,"elapsed":777,"user":{"displayName":"Alexey Skrynnik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb-e3rfdb-9cH-pDpsbPoNsHTSCgRXXeyYsgnk=s64","userId":"17884625855310505059"}},"outputId":"ec673b95-ffb0-4d28-aa74-ff4a29de92ab"},"source":["network = keras.models.Sequential()\n","network.add(L.InputLayer(state_dim))\n","# определяем граф вычислений, \n","# выходной слой должен быть без функции активации!\n","####### Здесь ваш код ##########\n","network.add(L.Dense(300, activation=\"relu\"))\n","network.add(L.Dense(n_actions))\n","################################"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PxestEGOY8VR","colab_type":"text"},"source":["Можем попробовать что-то предсказать:"]},{"cell_type":"code","metadata":{"id":"4MKym6ODX_Bk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1596737984878,"user_tz":-180,"elapsed":7530,"user":{"displayName":"Alexey Skrynnik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb-e3rfdb-9cH-pDpsbPoNsHTSCgRXXeyYsgnk=s64","userId":"17884625855310505059"}},"outputId":"943ad480-d0d8-4050-a990-e4b6b8a51cb9"},"source":["s1 = env.reset()\n","print(\"s1:\", s1)\n","\n","# приводим единственное состояние к формату батча\n","s1 = s1[None] # [[x1, x2, x3, x4]]\n","print(\"s1[None]:\", s1)\n","\n","# предсказываем значение [1]\n","print(\"predict:\", network.predict(s1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["s1: [ 0.01346599 -0.02807536 -0.01173901  0.02747713]\n","s1[None]: [[ 0.01346599 -0.02807536 -0.01173901  0.02747713]]\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","predict: [[-0.00483701  0.00203296]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rcZhESiN4zuE","colab":{}},"source":["import random\n","def get_action(network_, state, epsilon=0):\n","    \"\"\"\n","    сэмплируем (eps greedy) действие  \n","    \"\"\"\n","    # нужно выбрать действия eps-жадно, как мы делали в табличном Q-обучении\n","    # action = \n","    ####### Здесь ваш код ##########\n","    if epsilon < random.random():\n","      q_values = network_.predict(state[None])[0]\n","      action = np.argmax(q_values)\n","    else:\n","      action = random.choice(range(n_actions))\n","    ################################\n","    \n","    return action"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LpYxHgz642cZ","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1596738013164,"user_tz":-180,"elapsed":25419,"user":{"displayName":"Alexey Skrynnik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb-e3rfdb-9cH-pDpsbPoNsHTSCgRXXeyYsgnk=s64","userId":"17884625855310505059"}},"outputId":"28fc7a92-19f5-4e4a-87e0-52488e0a5967"},"source":["assert network.output_shape == (None, n_actions), \"Убедитесь, что стратегия переводит s -> [Q(s,a0), ..., Q(s, a_last)]\"\n","assert network.layers[-1].activation == keras.activations.linear, \"убедитесь, что вы предсказываете q без нелинейности\"\n","\n","# test epsilon-greedy exploration\n","s = env.reset()\n","assert np.shape(get_action(network, s)) == (), \"убедитесь, что возвращается только одно действие (типа integer)\"\n","for eps in [0., 0.1, 0.5, 1.0]:\n","    state_frequencies = np.bincount([get_action(network, s, epsilon=eps) for i in range(10000)], minlength=n_actions)\n","    best_action = state_frequencies.argmax()\n","    assert abs(state_frequencies[best_action] - 10000 * (1 - eps + eps / n_actions)) < 200\n","    for other_action in range(n_actions):\n","        if other_action != best_action:\n","            assert abs(state_frequencies[other_action] - 10000 * (eps / n_actions)) < 200\n","    print('e=%.1f tests passed'%eps)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["e=0.0 tests passed\n","e=0.1 tests passed\n","e=0.5 tests passed\n","e=1.0 tests passed\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JcAUZG5S5LmN"},"source":["Теперь будем приближать Q-функцию агента, минимизируя TD функцию потерь:\n","$$ L = { 1 \\over N} \\sum_i (Q_{\\theta}(s,a) - \\big [r(s,a) + \\gamma \\cdot max_{a'} Q_{-}(s', a')\\big ]) ^2,$$\n","где\n","* $s, a, r, s'$ состояние, действие, вознаграждение и следующее состояние \n","* $\\gamma$ дисконтирующий множетель.\n","\n","Основная тонкость состоит в использовании $Q_{-}(s',a')$. Эта та же самая функция, что и $Q_{\\theta}$, которая является выходом нейронной сети, но при обучении сети, мы не пропускаем через эти слои градиенты. Для этого используется функция tf.stop_gradient."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hpZjPiKP51_5","colab":{}},"source":["# Создаем placeholders для <s, a, r, s'>, \n","# не забываем про индикатор окончания эпизода (is_done = True)\n","states_ph = keras.backend.placeholder(dtype='float32', shape=(None,) + state_dim)\n","actions_ph = keras.backend.placeholder(dtype='int32', shape=[None])\n","rewards_ph = keras.backend.placeholder(dtype='float32', shape=[None])\n","next_states_ph = keras.backend.placeholder(dtype='float32', shape=(None,) + state_dim)\n","is_done_ph = keras.backend.placeholder(dtype='bool', shape=[None])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0MqsHE1w59un","colab":{}},"source":["# получаем q для всех действий, в текущем состоянии\n","predicted_qvalues = network(states_ph)\n","\n","# получаем q-values для выбранного действия\n","predicted_qvalues_for_actions = tf.reduce_sum(predicted_qvalues * tf.one_hot(actions_ph, n_actions), axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Gw_S5wXc6FUs","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1596738058147,"user_tz":-180,"elapsed":632,"user":{"displayName":"Alexey Skrynnik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjb-e3rfdb-9cH-pDpsbPoNsHTSCgRXXeyYsgnk=s64","userId":"17884625855310505059"}},"outputId":"8172ab16-469a-4017-f568-fdbb0dc3cc43"},"source":["gamma = 0.99\n","\n","# применяем сеть для получения q-value для next_states_ph\n","# predicted_next_qvalues =\n","####### Здесь ваш код ##########\n","predicted_next_qvalues = network(next_states_ph)\n","################################\n","\n","# вычисляем V*(next_states) \n","# по предсказанным next q-values \n","next_state_values = tf.reduce_max(predicted_next_qvalues, axis=1)\n","\n","# Вычисляем target q-values для функции потерь \n","# target_qvalues_for_actions = \n","####### Здесь ваш код ##########\n","target_qvalues_for_actions = rewards_ph + gamma * next_state_values\n","################################\n","\n","# для последнего значения в эпизоде используем упрощенную формулу Q(s,a) = r(s,a) \n","# if x : smth else \n","target_qvalues_for_actions = tf.where(is_done_ph, rewards_ph, target_qvalues_for_actions)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-20-2115ce9e9ba3>:21: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xO26mQWF61Rd","colab":{}},"source":["# mean squared error loss, который будем минимизировать\n","loss = (predicted_qvalues_for_actions - tf.stop_gradient(target_qvalues_for_actions)) ** 2\n","loss = tf.reduce_mean(loss)\n","\n","# применяем AdamOptimizer\n","train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VTImrMM77CTg","colab":{}},"source":["assert tf.gradients(loss, [predicted_qvalues_for_actions])[0] is not None, \"убедитесь, что обновление выполняется только для выбранного действия\"\n","assert tf.gradients(loss, [predicted_next_qvalues])[0] is None, \"убедитесь, что вы не распространяете градиент Q_(s',a')\"\n","assert predicted_next_qvalues.shape.ndims == 2, \"убедитесь, что вы предсказываете q для всех действий,следующего состояния\"\n","assert next_state_values.shape.ndims == 1, \"убедитесь, что вы вычислили V(s') как максимум только по оси действий, а не по всем осям\"\n","assert target_qvalues_for_actions.shape.ndims == 1, \"что-то не так с целевыми q-значениями, они должны быть вектором\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EqcQCsXb7lAH","colab":{}},"source":["def generate_session(env, t_max=1000, epsilon=0, train=False):\n","    total_reward = 0\n","    s = env.reset()\n","    \n","    for t in range(t_max):\n","        a = get_action(network, s, epsilon=epsilon)       \n","        next_s, r, done, _ = env.step(a)\n","        \n","        replay_buffer-.append((s, next_s, r, done))\n","        if train:\n","            sess.run(train_step,{\n","                states_ph: [s], actions_ph: [a], rewards_ph: [r], \n","                next_states_ph: [next_s], is_done_ph: [done]\n","            })\n","\n","        total_reward += r\n","        s = next_s\n","        if done:\n","            break\n","            \n","    return total_reward"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5XzMJKbP7s7g","colab":{"base_uri":"https://localhost:8080/","height":282},"outputId":"3e9bd553-f95a-4486-c3d0-62665fda5773"},"source":["sess.run(tf.global_variables_initializer())\n","\n","log = []\n","epsilon = 0.5\n","\n","for i in range(1, 100):\n","    session_rewards = [generate_session(env, epsilon=epsilon, train=True) for _ in range(100)]\n","    \n","    # Постепенно уменьшайте epsilon\n","    # epsilon =\n","    ####### Здесь ваш код ##########\n","    epsilon *= 0.99\n","    ################################\n","    assert epsilon >= 1e-4, \"убедитесь, что epsilon не становится < 0\"\n","    show_progress(session_rewards, log, reward_range=[0, 200])\n","    print(\"epoch #{}\\tmean reward = {:.3f}\\tepsilon = {:.3f}\".format(i, np.mean(session_rewards), epsilon))\n","    if np.mean(session_rewards) > 300:\n","        print(\"Принято!\")\n","        break"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["epoch #45\tmean reward = 160.220\tepsilon = 0.318\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AM3vch0F9LuN"},"source":["Интерпретация результатов\n","* mean reward - среднее вознаграждение за эпизод. В случае корректной реализации, этот показатель будет низким первые 5 эпох и только затем будет возрастать и сойдется на 30-50 эпохе в зависимости от архитектуры сети. \n","* Если сеть не достигает нужных результатов к концу цикла, попробуйте увеличить число нейронов в скрытом слое или поменяйте $\\epsilon$. \n","* epsilon -- обеспечивает стремление агента исследовать среду. "]}]}